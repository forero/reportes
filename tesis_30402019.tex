\documentclass{article}

\begin{document}
\title{Report on the thesis document presented by \\
Juan Pablo REYES G\'OMEZ}
\author{Written by Jaime E. FORERO ROMERO, PhD,\\
Associate Professor\\ Physics Department\\ Universidad de los Andes\\ Colombia}
\maketitle

The tesis by Juan Pablo REYES G\'OMEZ is entitled \emph{Astronomical image processing from large all-sky photometric surveys for the detection and measurement of type Ia supernovae}. 
It presents the author's work on the analysis of astronomical images and showcases its results as a contribution to the science efforts to be made with the upcoming Large Synoptic Survey Telescope (LSST).

The thesis is structured with 7 sections:
\begin{enumerate}
    \item Introduction (15 pages).
    \item Background (17 pages).
    \item Related Work (9 pages).
    \item Materials and Methods (27 pages).
    \item Results (18 pages).
    \item Discussion (4 pages).
    \item Perspectives (2 pages).
\end{enumerate}

There are also three appendices at the end. This puts already into a clear perspective that most of the document is dedicated to discuss the Methodology, a summary of the Results and a very short section of Discussion.
In the following paragraphs I will highlight the most relevant parts of each section.


{\bf The Introduction.} This section provides the general astronomical context to explicitly state the problem to be solved (page 11):
\begin{quote}
   "To address the problem of supernovae discovery in the LSST era, focusing on their use in cosmology analysis, we propose in this thesis work, to build, optimize and validate an automatic supernova detection pipeline based on the Stack". 
\end{quote}
it then sets as an specific objective (page 13):
\begin{quote}
    "Develop an efficient and accurate pipeline, based on the LSST Science Pipelines stack, to detect Type Ia supernova events on astronomical images for the LSST".
\end{quote}

The section end with a summary of the main methodological contributions and data products resulting from the author's work. 

{\bf Background.} This section starts by summarizing the
LSST Science Pipeline stack. Then, it presents the basic
transient detection pipeline already written by the LSST
Data Management team.
This pipeline implements the Alard and Lupton 1998 (AL98)
algorithm of image substraction. The two basic operations
behind the algorithm (image coaddition and substraction)
are also briefly presented here. The section then moves on
onto presenting four already existing  tools that will
be used later in the document: models of Type Ia
supernovae, supervised classification using random trees,
the sofware to generate the supernova light curves and the
Message Passing Interface for parallelism.

{\bf Related Work.} This section starts by presenting two kinds of transient events in astronomy: microlensing and supernovae. It then moves on to present other images substraction algorithms different from AL98 and algorihtms already published to distinguish Type Ia supernovae from other types of transients.

{\bf Materials and Methods}. This section is dedicated exclusively to describe the input datasets and the contribution by Mr. REYES G\'OMEZ. These datasets include:
\begin{itemize}
    \item Real images from one deep field from the Canada France Hawaii Telescope (CFHT) already available.
    \item Type Ia supernovae light curves already constructed from the CFHT imaging data.
    \item Simulated data of mock type Ia supernova imposed on real images (this is a new contribution from this thesis).
\end{itemize}

Then next subsection describes in detail the supernova detection pipeline. It highlights the author's contribution in each one of the three main steps:
\begin{itemize}
    \item Image subtraction. The main
    contribution is the optimization of the procedure and
    parameters that control already existing routines.
    \item Candidate selection. The main contribution is a new method to generate transient candidates and its light curves from the difference images.
    \item Type Ia supernovae identification. The main 
    contribution is the introduction of goodness-of-fit
    features (computed from the light curves from the difference images) as an input to a random forest
    classifier.
\end{itemize}
After such a detailed explanation of the main contributions the authors describes how was performed the impact evaluation:
\begin{itemize}
    \item The image subtraction are evaluated by the number of total detections and the percentage of positive/dipole features in those detections. These numbers are compared against the base pipeline.
    \item The candidate selection process is evaluated by the total number of candidates and compared against the expected values (known both in observations and simulations). The results are also compared against the base pipeline.
    \item The Type Ia supernova identification is evaluated by performance metrics based on the confusion matrix such as accuracy, precision, recall, F1-score and Receiver-Operating-Characteristic (ROC) curve.
\end{itemize}

{\bf Results.} This section summarizes the main results of the previous metrics.
\begin{itemize}
\item Image subtraction. Working on observational data the new pipeline makes 87042 detections while the base pipeline makes 4215406 detections. Results of the base and new pipeline on the the simulated images are not reported.
\item Candidate selection. The detections in the new pipeline misses 15\% of the true supernovae reported in observations. The detections in the new pipeline misses 25\% of the simulated supernovae injected in the images. Results from the base pipeline on the simulated images are not reported.
\item Type Ia supernova identifications. The training and testing set is a mixture of simulated supernovae and real non-supernovae. The are two validations sets: simulated supernovae and real non-supernovae; real supernovae and real non-supernovae. The new goodnes-of-fit features improvements of the order of 0.01 on the F1-score and ROC metric. 
\end{itemize}
The processing times for $~13000$ images of $4012\times 2048$ pixels is reported to be $~1100$ minutes on a small cluster of 30 nodes with 800 cores in total. 


The strong points of these thesis are:
\begin{itemize}
    \item Clear document.
\end{itemize}

The weak points are 
\begin{itemize}
    \item SDSS
\end{itemize}
\end{document}

